{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMVrCCn6UGlJgOvyzdWjUXB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yendruamarendra/Delta/blob/main/delta.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TASK 2"
      ],
      "metadata": {
        "id": "3ZOLaGnrbX0D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Install Pyspark\n"
      ],
      "metadata": {
        "id": "o9q3Z9QkXIZM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyspark py4j"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fWzBTfpoZVEO",
        "outputId": "194b57bc-0ed6-4c8d-cec0-b2669fe06c70"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pyspark\n",
            "  Downloading pyspark-3.3.1.tar.gz (281.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 281.4 MB 45 kB/s \n",
            "\u001b[?25hCollecting py4j\n",
            "  Downloading py4j-0.10.9.7-py2.py3-none-any.whl (200 kB)\n",
            "\u001b[K     |████████████████████████████████| 200 kB 49.4 MB/s \n",
            "\u001b[?25h  Downloading py4j-0.10.9.5-py2.py3-none-any.whl (199 kB)\n",
            "\u001b[K     |████████████████████████████████| 199 kB 15.7 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.3.1-py2.py3-none-any.whl size=281845512 sha256=fa82c6d951a4cd57f6a6250bc23365358c04e4699d39336d4adb66cd4c648a78\n",
            "  Stored in directory: /root/.cache/pip/wheels/43/dc/11/ec201cd671da62fa9c5cc77078235e40722170ceba231d7598\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.9.5 pyspark-3.3.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Imports"
      ],
      "metadata": {
        "id": "oWm4CrudXP9h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.shell import spark\n",
        "import pyspark.sql.functions as f\n",
        "from pyspark.sql.window import Window\n",
        "from pyspark.sql.functions import row_number\n",
        "from datetime import datetime"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dIWPHj83ZwBJ",
        "outputId": "0cbcca1e-bdb9-4e91-d5aa-93cf7143a58d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Welcome to\n",
            "      ____              __\n",
            "     / __/__  ___ _____/ /__\n",
            "    _\\ \\/ _ \\/ _ `/ __/  '_/\n",
            "   /__ / .__/\\_,_/_/ /_/\\_\\   version 3.3.1\n",
            "      /_/\n",
            "\n",
            "Using Python version 3.8.16 (default, Dec  7 2022 01:12:13)\n",
            "Spark context Web UI available at http://d805b4cbf3cc:4040\n",
            "Spark context available as 'sc' (master = local[*], app id = local-1671654377091).\n",
            "SparkSession available as 'spark'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "spark =  SparkSession.builder.appName(\"Delta_flights\").getOrCreate()"
      ],
      "metadata": {
        "id": "Na635lhraaYJ"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Read Flight leg Data as dataframe\n"
      ],
      "metadata": {
        "id": "lJ6Qkhv0Xck8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = spark.read.csv(\"/content/Delta/Dummy_Flight_Leg_Data.csv\",header = True, inferSchema=True)"
      ],
      "metadata": {
        "id": "qNlYqteNPvoy"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.count()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HEF0ATdhQIpn",
        "outputId": "075a04a1-a238-449b-8792-ade2ed1e0568"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "244080"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Considering flighkey as primary filtering out records for null if there are any"
      ],
      "metadata": {
        "id": "OwYNGjE8XmmG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.filter(f.col(\"flightkey\").isNotNull())"
      ],
      "metadata": {
        "id": "gB259Z_ifaVF"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Using window function for partition and order by"
      ],
      "metadata": {
        "id": "rQk208BmYBGp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "windowSpec = Window.partitionBy(\"flightkey\").orderBy(f.col(\"flight_dt\").desc(),f.col(\"lastupdt\").desc())"
      ],
      "metadata": {
        "id": "T4bN0WdQQgka"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating Column row_number over windowSpec and selection first record to get recent status of flights"
      ],
      "metadata": {
        "id": "QxbRXl9IYQX4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_res = df.withColumn(\"row_number\",row_number().over(windowSpec)).filter(\"row_number=1\").drop(\"row_number\")"
      ],
      "metadata": {
        "id": "zRIu9dl7dYCr"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Displaying records for all the flights with most recent status"
      ],
      "metadata": {
        "id": "jQxpqPv1YV0C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_res.count()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D_P-LiaRdvFh",
        "outputId": "fe51b029-9246-41e6-cef3-86b83bdd927b"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "244078"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## USING SQL - TASK 1"
      ],
      "metadata": {
        "id": "oR4QAdlfa71S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.createOrReplaceTempView(\"flight\")"
      ],
      "metadata": {
        "id": "1GAQYegNYgod"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark.sql(\"\"\"SELECT * FROM ( \n",
        "  SELECT *, ROW_NUMBER() \n",
        "  OVER(PARTITION BY flightkey ORDER BY flight_dt desc,lastupdt DESC) AS row_number \n",
        "  FROM flight ) temp \n",
        "WHERE Row_number=1\"\"\").count()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qywy7IpXYnog",
        "outputId": "78e47817-2322-4fb8-f98f-54981d9cf5b3"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "244078"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    }
  ]
}